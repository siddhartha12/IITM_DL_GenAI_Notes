{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "qSQqhXoY9KHJ",
   "metadata": {
    "id": "qSQqhXoY9KHJ",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# L1.1 - Introduction to ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336a0f22-f41a-42f0-96a5-8072d5ad9d41",
   "metadata": {
    "id": "336a0f22-f41a-42f0-96a5-8072d5ad9d41"
   },
   "source": [
    "Machine learning is the field of study that gives computers the abiity to learn without being explicitly programmed. i.e. learn directly from data, no explicitly programed rules\n",
    "## Data and process\n",
    "### Focus: Structured data\n",
    "* Data in Tables (rows and columns)\n",
    "* Predict a target from features\n",
    "\n",
    "### Method: manual feature engineering\n",
    "* Human experts design features\n",
    "* model learns from these engineered features\n",
    "* success depends on feature quaity\n",
    "\n",
    "## Models\n",
    "### Linear models\n",
    "* core idea: assumes linear relationships\n",
    "* eg: linear/logistic regression\n",
    "* traits: fast, interpretable but simple\n",
    "### Tree Based models\n",
    "* core idea: learns if-then-else rules\n",
    "traits: capture non linearity\n",
    "\n",
    "## Limitations\n",
    "### Feature engineering Bottleneck\n",
    "Time consuming, requires domain expertise and is often suboptimal\n",
    "### Inability to handle high dimension data\n",
    "struggles with images, audio, or raw text\n",
    "### Limited representation learning\n",
    "learn shallow patterns, not deep hierarchical features\n",
    "## New paradigm\n",
    "ML needs manual feature extraction, DL learns them automatically\n",
    "\n",
    "## Deep Learning\n",
    "* Models learn directly from raw data\n",
    "* Handles images, text and audio\n",
    "* no manual feature extraction\n",
    "\n",
    "## Factors for Deep learning\n",
    "* Big data\n",
    "* computational power\n",
    "* Better algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6599400a-72cf-432b-bd11-9d97a5572cb0",
   "metadata": {
    "id": "6599400a-72cf-432b-bd11-9d97a5572cb0",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# L1.2 - Introduction to PyTorch and Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b716c8a1-745b-4a0f-b7dd-8fb16e065c19",
   "metadata": {
    "id": "b716c8a1-745b-4a0f-b7dd-8fb16e065c19"
   },
   "source": [
    "## Advantages of PyTorch\n",
    "* dynamic computational graphs allow for flexible model architectures\n",
    "* pythonic interface that integrates seamleslly with the python ecosystem\n",
    "* Extensive debugging capabilities with standard python debugging tools\n",
    "\n",
    "## Performance Optimization\n",
    "* Efficient GPU integration through cuda integration\n",
    "* optimized tensors operatins for numerical computations\n",
    "* Support for distributed training across multiple devices\n",
    "\n",
    "## Theoretical foundation\n",
    "tensors are used to represent\n",
    "\n",
    "## Notation\n",
    "* Scalar: lowercase italic\n",
    "* vector: lowercase bold letters\n",
    "* matrices: Uppercase bold letters\n",
    "* Tensors: Uppercase bold letters with rank notation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2c1435-24e8-447e-9b14-d957202cba43",
   "metadata": {
    "id": "ff2c1435-24e8-447e-9b14-d957202cba43",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# L1.3 Pytorch environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oNmXdSLuA4nB",
   "metadata": {
    "id": "oNmXdSLuA4nB"
   },
   "source": [
    "ON Computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g2yW2dQV9Wak",
   "metadata": {
    "id": "g2yW2dQV9Wak",
    "outputId": "5a7a7612-fe76-4450-8761-4c539eade99b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.8.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3fb7993-0cda-4bde-87ee-2e50d9eda61c",
   "metadata": {
    "id": "d3fb7993-0cda-4bde-87ee-2e50d9eda61c",
    "outputId": "d7618fe8-2ad5-4740-baa6-8d232ca23e0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version 2.2.3\n",
      "matplotlib version 3.10.1\n"
     ]
    }
   ],
   "source": [
    "# Additional libraries\n",
    "# numpy for numerical operarions\n",
    "import numpy as np\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "print(f\"numpy version {np.__version__}\")\n",
    "print(f\"matplotlib version {matplotlib.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e605af26-9d49-44ee-9e04-c706293481f4",
   "metadata": {
    "id": "e605af26-9d49-44ee-9e04-c706293481f4",
    "outputId": "fc900e56-fc79-4331-a15d-66562d2dc5b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU availability\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DENrQJ8MA6JO",
   "metadata": {
    "id": "DENrQJ8MA6JO"
   },
   "source": [
    "ON Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f8ea981-ffa2-4a6a-86b6-bf51487b0fbb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4f8ea981-ffa2-4a6a-86b6-bf51487b0fbb",
    "outputId": "d637690f-03af-49ca-a322-56fd44b1fea3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.8.0+cu126\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aKSCf5GNA84x",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aKSCf5GNA84x",
    "outputId": "98e3afca-eaa8-43c7-b8fe-d3b6b6559485"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU availability\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f55daf-d2f8-40bd-be05-5021a2db5d43",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# L1.4 - Tensor creation methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fbf4f9-9f7d-4c14-97d3-d428ec709ac0",
   "metadata": {},
   "source": [
    "Tensor creation forms the foundation of any deep learning workflow, proving mechanism to:\n",
    "1. Initialize data structures for inputs, parameters and outputs\n",
    "2. control numerical precision through data type specification\n",
    "3. optimize memory usage through appropricate tensor sizing\n",
    "4. ensure model reproducibility through deterministic initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "RYarTxgoBEgm",
   "metadata": {
    "id": "RYarTxgoBEgm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]])\n"
     ]
    }
   ],
   "source": [
    "# scalar\n",
    "scalar = torch.tensor(7)\n",
    "print(scalar)\n",
    "\n",
    "# vector\n",
    "vector = torch.tensor([1,2,3,4])\n",
    "print(vector)\n",
    "\n",
    "# matrix\n",
    "matrix = torch.tensor([\n",
    "    [1,2],\n",
    "    [3,4]\n",
    "])\n",
    "print(matrix)\n",
    "\n",
    "# 3D tensor\n",
    "tensor = torch.tensor([\n",
    "    [[1,2],[3,4]],\n",
    "    [[5,6],[7,8]]\n",
    "])\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8fa4dce-a249-40ec-81f0-f14f9a778baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bb3181b-c159-4e16-8e5c-5320f01467ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0acc2f72-66f9-4bef-b620-0ce8214c63b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# Data type specification\n",
    "float_tensor = torch.tensor([1.0,2.0,3.0], dtype=torch.float32)\n",
    "\n",
    "print(float_tensor.element_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3423d42-cb35-43c8-a702-e7816e5215a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Numpy to Tensor\n",
    "np_array = np.array([[1,2,3],[4,5,6]])\n",
    "\n",
    "tensor_from_numpy = torch.from_numpy(np_array)\n",
    "\n",
    "print(tensor_from_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8aef347-2d13-4cff-b9b4-8b8cbacc1e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[100,   2,   3],\n",
      "        [  4,   5,   6]])\n"
     ]
    }
   ],
   "source": [
    "# memory is shared\n",
    "np_array[0, 0] = 100\n",
    "print(tensor_from_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22f5d343-bd92-4fac-94ce-4a814946e68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[42, 42],\n",
      "        [42, 42],\n",
      "        [42, 42]])\n"
     ]
    }
   ],
   "source": [
    "# Create empty, ones, zeros tensors\n",
    "\n",
    "# zeros tensor\n",
    "zeros_tensor = torch.zeros(3,3)\n",
    "print(zeros_tensor)\n",
    "\n",
    "ones_tensor = torch.ones(3,3)\n",
    "print(ones_tensor)\n",
    "\n",
    "# doesnt initialize null values, \n",
    "# just chooses addresses in memory and displays whatever the hell is on there\n",
    "empty_tensor = torch.empty(2,2)\n",
    "print(empty_tensor)\n",
    "\n",
    "filled_tensor = torch.full((3,2), 42)\n",
    "print(filled_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a55039b-5adb-4631-a67a-8cf0929fba40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identity matrices\n",
    "I = torch.eye(3)\n",
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8829e39c-8580-4aa1-8763-3ffd808d724d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# non square identity\n",
    "I2 = torch.eye(2,4)\n",
    "I2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22c61bde-c5f2-47ca-96a5-43555bb7ab94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating sequential tensors\n",
    "\n",
    "# 1. linear spacing\n",
    "# tensor with 5 valus evenly spaced between 0 and 1\n",
    "linear_tensor = torch.linspace(0,1,5)\n",
    "linear_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1515ecdb-7782-46f6-a338-af9ec6390e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   10.,   100.,  1000., 10000.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. logarithmic spacing\n",
    "log_tensor = torch.logspace(1, 4, 4)\n",
    "log_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97686794-d8bb-4e56-bb30-20cbd530f24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. arrange values from 0 to 9\n",
    "range_tensor = torch.arange(0,9)\n",
    "range_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2baeef21-d854-476d-b6c2-793529d1057e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 1.7500, 3.5000, 5.2500, 7.0000, 8.7500])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Step tensor\n",
    "step_tensor = torch.arange(0, 10, 1.75)\n",
    "step_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77a1135c-2134-4d66-a8b9-f8c67f367188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0],\n",
       "        [0, 2, 0],\n",
       "        [0, 0, 3]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Diagonmal matrices\n",
    "diag = torch.diag(torch.tensor([1,2,3]))\n",
    "diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7df0a7b-14e5-4d52-8c60-1a762a488451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 5, 9])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = torch.tensor([\n",
    "    [1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9]\n",
    "])\n",
    "torch.diag(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98889975-98a2-49a9-b0eb-a57170dd0199",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# L1.5 - Tensor Manipulation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7be94a42-9fe7-4330-958f-cdc20cd3f0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3497, 0.9385, 0.8205, 0.3868],\n",
       "        [0.3590, 0.1507, 0.6423, 0.8876],\n",
       "        [0.0165, 0.6045, 0.7368, 0.3323]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# Random Tensor\n",
    "rand_tensor = torch.rand(size=(3,4))\n",
    "rand_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "929afe83-b00f-420b-a45d-c462af600be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min value: 0.016495\n",
      "Max value: 0.938481\n",
      "mean value: 0.518757\n",
      "sigma value: 0.296565\n"
     ]
    }
   ],
   "source": [
    "print(f\"Min value: {torch.min(rand_tensor).item():.6f}\")\n",
    "\n",
    "print(f\"Max value: {torch.max(rand_tensor).item():.6f}\")\n",
    "\n",
    "print(f\"mean value: {torch.mean(rand_tensor).item():.6f}\")\n",
    "\n",
    "print(f\"sigma value: {torch.std(rand_tensor).item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9a4ee72-224c-4ef0-98db-d428e2764952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theoretical std: 0.288675\n"
     ]
    }
   ],
   "source": [
    "# Theoretical std\n",
    "theoretical_std = 1.0/(12 ** 0.5)\n",
    "print(f\"Theoretical std: {theoretical_std:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c971a03-5c4f-42cf-8e0f-52b6a784b7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor: tensor([[[0.7207, 0.5879, 0.5509],\n",
      "         [0.0262, 0.2247, 0.2531],\n",
      "         [0.9825, 0.4592, 0.8357],\n",
      "         ...,\n",
      "         [0.3068, 0.3260, 0.9011],\n",
      "         [0.2741, 0.4767, 0.2637],\n",
      "         [0.1384, 0.5522, 0.8968]],\n",
      "\n",
      "        [[0.2918, 0.5903, 0.5991],\n",
      "         [0.1710, 0.9614, 0.9425],\n",
      "         [0.8386, 0.0910, 0.0216],\n",
      "         ...,\n",
      "         [0.1384, 0.9036, 0.6075],\n",
      "         [0.1949, 0.0901, 0.8175],\n",
      "         [0.5470, 0.7143, 0.2584]],\n",
      "\n",
      "        [[0.9564, 0.7055, 0.2621],\n",
      "         [0.4984, 0.6837, 0.8362],\n",
      "         [0.7403, 0.2765, 0.1719],\n",
      "         ...,\n",
      "         [0.3088, 0.7172, 0.4323],\n",
      "         [0.0612, 0.1075, 0.0787],\n",
      "         [0.0738, 0.4626, 0.7423]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0538, 0.8010, 0.5307],\n",
      "         [0.6675, 0.3210, 0.6036],\n",
      "         [0.4021, 0.3645, 0.1297],\n",
      "         ...,\n",
      "         [0.3662, 0.7464, 0.5394],\n",
      "         [0.3449, 0.6532, 0.2733],\n",
      "         [0.1032, 0.8769, 0.9875]],\n",
      "\n",
      "        [[0.2987, 0.5662, 0.3114],\n",
      "         [0.5840, 0.7161, 0.3661],\n",
      "         [0.4801, 0.5991, 0.5448],\n",
      "         ...,\n",
      "         [0.1452, 0.2681, 0.9684],\n",
      "         [0.4506, 0.7433, 0.5410],\n",
      "         [0.9580, 0.1338, 0.3635]],\n",
      "\n",
      "        [[0.6670, 0.9408, 0.7966],\n",
      "         [0.3078, 0.0250, 0.2863],\n",
      "         [0.7757, 0.9629, 0.0038],\n",
      "         ...,\n",
      "         [0.7580, 0.6416, 0.3596],\n",
      "         [0.7016, 0.8300, 0.8197],\n",
      "         [0.3976, 0.3954, 0.2931]]])\n"
     ]
    }
   ],
   "source": [
    "# Computer vision\n",
    "random_image_size_tensor = torch.rand(size=(224,224,3))\n",
    "print(f\"tensor: {random_image_size_tensor}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "313cdd2a-0555-4046-a01a-8fcb2e977187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bytes per element\n",
    "random_image_size_tensor.element_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fb8fc88-2ec9-4ec1-853e-ce9c8689dc2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "602112"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total memory \n",
    "random_image_size_tensor.numel() * random_image_size_tensor.element_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b36a87-d8d6-41f2-a259-955e41eb4c50",
   "metadata": {},
   "source": [
    "Standard image formats in deep learning\n",
    "* Imagenet standard: 224x 224x3\n",
    "* CIFAR-10: 32x32x3\n",
    "* MNIST: 28x28x1\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efde865d-7136-4527-8209-67907eec9d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "zero_to_ten = torch.arange(start=0, end=10, step=1)\n",
    "zero_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef38d7bd-d1e7-4950-acec-2475f223eac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a tensor of a similar shape to the input tensor\n",
    "ten_zeros = torch.zeros_like(input=zero_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13895fdd-b8aa-4b2b-b0fa-c98cdbb8a7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor = torch.tensor([3.0,6.0,9.0],\n",
    "                               dtype=None,\n",
    "                               device=None,\n",
    "                               requires_grad=False)\n",
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e36d53d-a534-4d33-ad32-a247ca32c316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# additiona\n",
    "tensor = torch.tensor([1,2,3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ed05a83-3a56-4972-b1a2-9b3c477ab443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ee8e99c-1fe3-43d6-9f3e-f0b0ea5e1f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Built functions\n",
    "torch.multiply(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bd48508-aa20-40f5-bf69-b2256627046f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "self must be a matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m torch\u001b[38;5;241m.\u001b[39mmatmul(A, B)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Notation 2 only for 2D\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# notation 2\u001b[39;00m\n\u001b[0;32m      9\u001b[0m A \u001b[38;5;241m@\u001b[39m B\n",
      "\u001b[1;31mRuntimeError\u001b[0m: self must be a matrix"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "A = torch.tensor([0, 1, 2])\n",
    "B = torch.tensor([[0], [1], [2]])\n",
    "# Notation 1 (dimensions must be compatiable)\n",
    "torch.matmul(A, B)\n",
    "# Notation 2 only for 2D\n",
    "torch.mm(A, B)\n",
    "# notation 2\n",
    "A @ B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158ffc69-936c-4a6c-a65e-61c85a7a601d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# L1.6 - Reshaping methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6507dc0-5ef2-433e-b01f-ec418c69a3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.arange(1., 8)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88b45d2c-3558-4a5a-b31c-ac3ef7b0806a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.reshape(1,7)\n",
    "y, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a39cbbb4-662a-442d-a4b6-730635a2151a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x.view(1,7)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6858bc1-1cc5-421b-b8ab-f31fd216d544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7.]]), tensor([5., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[:, 0] = 5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de859990-d9b2-49a5-abc6-5f25de1ada6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5., 69.,  3.,  4.,  5.,  6.,  7.]]),\n",
       " tensor([ 5., 69.,  3.,  4.,  5.,  6.,  7.]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:,1] = 69\n",
    "y, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "936007d1-e6d2-4ce8-b538-eb1f9f603096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5., 69.,  3.,  4.,  5.,  6.,  7.],\n",
       "        [ 5., 69.,  3.,  4.,  5.,  6.,  7.],\n",
       "        [ 5., 69.,  3.,  4.,  5.,  6.,  7.],\n",
       "        [ 5., 69.,  3.,  4.,  5.,  6.,  7.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs0 = torch.stack([x, x, x, x], dim=0)\n",
    "xs0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a32cabe4-3ffd-461c-93f9-228e039c90ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  5.,  5.,  5.],\n",
       "        [69., 69., 69., 69.],\n",
       "        [ 3.,  3.,  3.,  3.],\n",
       "        [ 4.,  4.,  4.,  4.],\n",
       "        [ 5.,  5.,  5.,  5.],\n",
       "        [ 6.,  6.,  6.,  6.],\n",
       "        [ 7.,  7.,  7.,  7.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs1 = torch.stack([x, x, x, x], dim=1)\n",
    "xs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "839bdb93-abe8-4ff8-af38-e3857ea0bfc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 7]), torch.Size([7, 4]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs0.shape, xs1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e954363b-606f-44ab-bcd0-94b46077bfb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 7]),\n",
       " torch.Size([7]),\n",
       " tensor([ 5., 69.,  3.,  4.,  5.,  6.,  7.]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# squeeze\n",
    "x_squeeze = y.squeeze()\n",
    "y.shape, x_squeeze.shape, x_squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0aa84262-5342-49f2-8f85-ad122c28fa5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5.],\n",
       "         [69.],\n",
       "         [ 3.],\n",
       "         [ 4.],\n",
       "         [ 5.],\n",
       "         [ 6.],\n",
       "         [ 7.]]),\n",
       " torch.Size([7, 1]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x_squeeze.unsqueeze(dim=1)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74475e85-86ef-4327-a143-c904d20abfa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), torch.Size([3, 224, 224]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(size=[224,224,3])\n",
    "y = x.permute(2,0,1)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e79488c-78ff-4ed7-ba3b-265a59ed40b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1,10).reshape(1,3,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd18c184-9866-47e7-b97a-5985207224ff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# L1.7 - PyTorch and NumPy Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50b076c8-81be-4db9-8441-55b0beb71144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "# From numpy to tensor\n",
    "x = np.arange(1,8)\n",
    "t = torch.from_numpy(x)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3767dc67-2c8e-4612-93a5-ad26d234a4e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From tensor to numpy\n",
    "y = t.numpy()\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7166b72e-6e67-4e5f-aadb-b8d5e2e389cd",
   "metadata": {},
   "source": [
    "# L1.8 - Reproducibility in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa05d649-0397-4c18-aa26-ac468f2e6bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
       "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
       "        [0.9408, 0.1332, 0.9346, 0.5936]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "random_tensor_a = torch.rand(3,4)\n",
    "\n",
    "random_tensor_a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefec129-86ef-4466-af3e-63777c894a65",
   "metadata": {},
   "source": [
    "# L1.9 Hardware Acceleratio in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9cce676-4487-4119-b00f-172c8410155e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ba00ec-515c-42f1-9d62-3f157e1c407f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
